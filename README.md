# 🤖 Reinforcement Learning Projects

Welcome to my collection of Reinforcement Learning (RL) projects! This repository features practical implementations of core RL algorithms inspired by Sutton & Barto’s classic book *Reinforcement Learning: An Introduction*. Each sub-project is designed to illustrate key RL concepts using simple environments.

---

## 📁 Projects Overview

| Project | Description | Algorithms |
|--------|-------------|------------|
| [🃏 Blackjack](./projects/blackjack) | Train an agent to play simplified Blackjack using Gym. | Q-Learning, Deep Q-Network (DQN) |
| [🚶‍♂️ Random Walk](./projects/random-walk) | Estimate value functions in a linear environment. | Monte Carlo, TD(0), n-step TD, TD(λ) |
| [🌬️ Windy Gridworld](./projects/windy-gridworld) | Navigate a grid under wind forces. | SARSA, Q-Learning, Expected SARSA |
| [🎰 Gambler's Problem](./projects/gambler-problem) | Optimal betting strategy problem. | Dynamic Programming |
| [🗺️ Gridworld (DP)](./projects/gridworld-dp) | Solve Gridworld using full model knowledge. | Value Iteration, Policy Iteration |
| [📊 Gridworld (MDP)](./projects/gridworld-mdp) | Model Gridworld as an MDP. | MDP Framework, Bellman Updates |
| [🎯 10-Armed Testbed](./projects/ten-armed-testbed) | Explore action selection strategies in a multi-armed bandit setup. | ε-greedy, UCB, Optimistic Init |
| [❌⭕ Tic-Tac-Toe](./projects/tic-tac-toe) | Learn to play Tic-Tac-Toe through self-play. | Tabular Value Function |
| [🌄 Cliff Walking](./projects/cliff-walking) | Navigate a cliff-edge environment. | SARSA, Q-Learning |
| [♾️ Infinite Variance](./projects/infinite-variance) | Explore scenarios leading to infinite variance in Monte Carlo estimates. | Monte Carlo Methods |

---


## 🚀 Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Narek889/Reinforcement-Learning.git
cd Reinforcement-Learning
```
---

## 🤖 What is Reinforcement Learning?

**Reinforcement Learning (RL)** is a type of machine learning where an **agent** learns to make decisions by interacting with an **environment** to maximize a **reward**. It’s based on trial and error, learning from experience.

---
